{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./asd.png\" style=\"width: 70%\"> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 99 finished after 181 timesteps\n",
      "Episode 199 finished after 36 timesteps\n",
      "Episode 299 finished after 133 timesteps\n",
      "Episode 399 finished after 109 timesteps\n",
      "Episode 499 finished after 227 timesteps\n",
      "Episode 599 finished after 500 timesteps\n",
      "Episode 699 finished after 211 timesteps\n",
      "Episode 799 finished after 289 timesteps\n",
      "Episode 899 finished after 127 timesteps\n",
      "Episode 999 finished after 149 timesteps\n",
      "Episode 1099 finished after 40 timesteps\n",
      "Episode 1199 finished after 102 timesteps\n",
      "Episode 1299 finished after 159 timesteps\n",
      "Episode 1399 finished after 500 timesteps\n",
      "Episode 1499 finished after 462 timesteps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-816e50920394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m#     writer = SummaryWriter()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_episodic_A2C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-816e50920394>\u001b[0m in \u001b[0;36mlearn_episodic_A2C\u001b[0;34m(N_eps, max_ep_steps)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtotal_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-816e50920394>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSavedAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_pmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.action_head = nn.Linear(128, 2)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def forward(self, x, only_value=False):\n",
    "        if only_value:\n",
    "            with torch.no_grad():\n",
    "                x = F.relu(self.affine1(x))\n",
    "                state_values = self.value_head(x)\n",
    "                return state_values\n",
    "\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        return F.softmax(action_scores, dim=-1), state_values\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=3e-3)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    probs, state_value = policy(state)\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "    return action.item()\n",
    "\n",
    "\"GIVEN rewards array from rollout return the returns with zero mean and unit std\"        \n",
    "def discount_rewards(rewards_arr, gamma, start_value, dones):\n",
    "#     print(len(dones))\n",
    "#     print(len(rewards_arr))\n",
    "    assert len(dones) == len(rewards_arr), \"qqq\"\n",
    "    R = start_value\n",
    "    returns = []\n",
    "    for i in reversed(range(len(rewards_arr))):\n",
    "        r = rewards_arr[i]\n",
    "        done = dones[i]\n",
    "        if done:\n",
    "            R = 0\n",
    "        R = r + R*gamma\n",
    "        returns.insert(0, R)\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean())/(returns.std() + 1e-5)\n",
    "    return returns\n",
    "\n",
    "def discount_rewards_2(rewards_arr, gamma):\n",
    "#     print(len(dones))\n",
    "#     print(len(rewards_arr))\n",
    "\n",
    "    for i in reversed(range(len(rewards_arr))):\n",
    "        r = rewards_arr[i]\n",
    "        R = r + R*gamma\n",
    "        returns.insert(0, R)\n",
    "    returns = torch.tensor(returns)\n",
    "    returns = (returns - returns.mean())/(returns.std() + 1e-5)\n",
    "    return returns\n",
    "\n",
    "def train_on_rollout(gamma=0.99):\n",
    "    returns = discount_rewards_2(policy.rewards, gamma)\n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "    del policy.dones[:]\n",
    "\n",
    "def train_on_batch(observation, done, gamma, T):\n",
    "    returns = None\n",
    "    if done:\n",
    "        returns = discount_rewards(policy.rewards, gamma, 0, policy.dones)\n",
    "    else:\n",
    "        next_state = torch.from_numpy(observation).float()\n",
    "        final_value = policy(next_state, only_value=True)\n",
    "        returns = discount_rewards(policy.rewards, gamma, final_value.item(), policy.dones)\n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.mse_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss_actor = torch.stack(actor_loss).mean()\n",
    "#     writer.add_scalar(\"actor loss\", loss_actor, T)\n",
    "    loss_critic = torch.stack(critic_loss).mean()\n",
    "#     writer.add_scalar(\"critic loss\", loss_actor, T)\n",
    "    loss = loss_actor + loss_critic\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "    del policy.dones[:]\n",
    "\n",
    "def learn_episodic_A2C(N_eps, max_ep_steps):\n",
    "    df = 0.99\n",
    "    rewards = []\n",
    "    env = gym.make('CartPole-v0')\n",
    "    batch_update = 50\n",
    "    env._max_episode_steps = max_ep_steps\n",
    "    T = 1\n",
    "    for i_episode in range(N_eps):\n",
    "        observation = env.reset()\n",
    "        total_r = 0\n",
    "        for t in range(100000):\n",
    "            action = select_action(observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            policy.dones.append(done)\n",
    "            policy.rewards.append(reward)\n",
    "            total_r += reward\n",
    "            if T % batch_update == 0:\n",
    "                train_on_batch(observation, done, df, T)\n",
    "            T += 1\n",
    "            if done:\n",
    "#                 train_on_rollout(0.99)\n",
    "                if (i_episode + 1) % 100 == 0:                \n",
    "                    print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "                break\n",
    "#         writer.add_scalar(\"Ep reward\", total_r, i_episode)\n",
    "\n",
    "    # writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "#     writer.close()\n",
    "    env.close()\n",
    "    return rewards\n",
    "# N_EPS = 2000\n",
    "# rewards_A2C = learn_episodic_A2C(N_EPS, 500)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     writer = SummaryWriter()\n",
    "    rewards = learn_episodic_A2C(5000, 500)\n",
    "    print(rewards)\n",
    "    plt.plot(np.arange(len(rewards)), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 99 finished after 120 timesteps\n",
      "Episode 199 finished after 186 timesteps\n",
      "Episode 299 finished after 210 timesteps\n",
      "Episode 399 finished after 101 timesteps\n",
      "Episode 499 finished after 112 timesteps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3be50910>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.action_head = nn.Linear(128, 2)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        return F.softmax(action_scores, dim=-1), state_values\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=3e-3)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    probs, state_value = policy(state)\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "    return action.item()\n",
    "\n",
    "\"GIVEN rewards array from rollout return the returns with zero mean and unit std\"        \n",
    "def discount_rewards(rewards_arr, dones, gamma, final_value=0):\n",
    "    R = final_value\n",
    "    returns = []\n",
    "    zipped = list(zip(rewards_arr, dones))\n",
    "    for (r, done) in zipped[::-1]:\n",
    "        if done:\n",
    "            R = 0\n",
    "        R = r + R*gamma\n",
    "        returns.insert(0, R)\n",
    "#     print('rewards_arr', rewards_arr)\n",
    "    returns = torch.tensor(returns)\n",
    "    return (returns - returns.mean())/(returns.std() + eps)\n",
    "\n",
    "def train_on_rollout(gamma=0.99):\n",
    "    returns = discount_rewards(policy.rewards, gamma)\n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "    \n",
    "def train_on_batch(gamma=0.99, final_obs=None, done=True):\n",
    "    state = torch.from_numpy(final_obs).float()\n",
    "    _, state_value = policy(state)\n",
    "    final_value = state_value.detach() if not done else 0.0\n",
    "    \n",
    "    returns = discount_rewards(policy.rewards, policy.dones, gamma, final_value)\n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "    loss.mean().backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "    del policy.dones[:]\n",
    "\n",
    "def learn_episodic_A2C(N_eps=500, max_ep_steps=500):\n",
    "    df = 0.99\n",
    "    rewards = []\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env._max_episode_steps = max_ep_steps\n",
    "    T = 0\n",
    "    batch_update_freq = 30\n",
    "\n",
    "    for i_episode in range(N_eps):\n",
    "        observation = env.reset()\n",
    "        total_r = 0\n",
    "        for t in range(100000):\n",
    "            T += 1\n",
    "            action = select_action(observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            policy.rewards.append(reward)\n",
    "            policy.dones.append(done)\n",
    "            total_r += reward\n",
    "            if T % batch_update_freq == 0:\n",
    "                train_on_batch(0.99, observation, done=True)\n",
    "            if done:\n",
    "#                 train_on_batch(0.99, observation, done)\n",
    "                if (i_episode + 1) % 100 == 0:                \n",
    "                    print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "                break\n",
    "        rewards.append(total_r)\n",
    "    env.close()\n",
    "    return rewards\n",
    "rewards_A2C = learn_episodic_A2C(N_EPS, 500)\n",
    "plt.plot(rewards_A2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.action_head = nn.Linear(128, 2)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.states = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        return F.softmax(action_scores, dim=-1), state_values\n",
    "\n",
    "policy = Policy()\n",
    "policy_old = Policy()\n",
    "policy_old.load_state_dict(policy.state_dict())\n",
    "\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=3e-3)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    probs, state_value = policy_old(state)\n",
    "    m = Categorical(probs)\n",
    "    action = m.sample()\n",
    "    policy.actions.append(action.item())\n",
    "    policy.log_probs.append(m.log_prob(action).item())\n",
    "    policy.states.append(state)\n",
    "#     policy.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "    return action.item()\n",
    "\n",
    "\"GIVEN rewards array from rollout return the returns with zero mean and unit std\"        \n",
    "def discount_rewards(rewards_arr, dones, gamma, final_value=0):\n",
    "    R = final_value\n",
    "    returns = []\n",
    "    zipped = list(zip(rewards_arr, dones))\n",
    "    for (r, done) in zipped[::-1]:\n",
    "        if done:\n",
    "            R = 0\n",
    "        R = r + R*gamma\n",
    "        returns.insert(0, R)\n",
    "#     print('rewards_arr', rewards_arr)\n",
    "    returns = torch.tensor(returns)\n",
    "    return (returns - returns.mean())/(returns.std() + eps)\n",
    "\n",
    "# def train_on_rollout(gamma=0.99):\n",
    "#     returns = discount_rewards(policy.rewards, gamma)\n",
    "#     actor_loss = []\n",
    "#     critic_loss = []\n",
    "#     for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "#         advantage = r - value.item()\n",
    "#         actor_loss.append(-log_prob * advantage)\n",
    "#         critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "#     optimizer.zero_grad()\n",
    "#     loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     del policy.rewards[:]\n",
    "#     del policy.saved_actions[:]\n",
    "    \n",
    "# def train_on_batch(gamma=0.99, final_obs=None, done=True):\n",
    "#     state = torch.from_numpy(final_obs).float()\n",
    "#     _, state_value = policy(state)\n",
    "#     final_value = state_value.detach() if not done else 0.0\n",
    "    \n",
    "#     returns = discount_rewards(policy.rewards, policy.dones, gamma, final_value)\n",
    "#     actor_loss = []\n",
    "#     critic_loss = []\n",
    "#     for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "#         advantage = r - value.item()\n",
    "#         actor_loss.append(-log_prob * advantage)\n",
    "#         critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "#     optimizer.zero_grad()\n",
    "#     loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "#     loss.mean().backward()\n",
    "#     optimizer.step()\n",
    "#     del policy.rewards[:]\n",
    "#     del policy.saved_actions[:]\n",
    "#     del policy.dones[:]\n",
    "def evaluate_policy():\n",
    "    \n",
    "    # returns state_values, \n",
    "\n",
    "def train_ppo(gamma=0.99, final_obs=None, done=True):\n",
    "    state = torch.from_numpy(final_obs).float()\n",
    "    _, state_value = policy(state)\n",
    "    final_value = state_value.detach() if not done else 0.0\n",
    "    returns = discount_rewards(policy.rewards, policy.dones, gamma, final_value)\n",
    "    \n",
    "    \n",
    "    # PPO OLD VALUES\n",
    "    for i in range(4):\n",
    "        \n",
    "        # compute loss for clip params\n",
    "        \n",
    "        # compute loss for value function\n",
    "        \n",
    "        # compute entropy bonus\n",
    "        \n",
    "    \n",
    "\n",
    "def learn_episodic_A2C(N_eps=500, max_ep_steps=500):\n",
    "    df = 0.99\n",
    "    rewards = []\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env._max_episode_steps = max_ep_steps\n",
    "    T = 0\n",
    "    batch_update_freq = 30\n",
    "\n",
    "    for i_episode in range(N_eps):\n",
    "        observation = env.reset()\n",
    "        total_r = 0\n",
    "        for t in range(100000):\n",
    "            T += 1\n",
    "            action = select_action(observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            policy.rewards.append(reward)\n",
    "            policy.dones.append(done)\n",
    "            total_r += reward\n",
    "            if T % batch_update_freq == 0:\n",
    "                train_ppo(0.99, observation, done=True)\n",
    "            if done:\n",
    "#                 train_on_batch(0.99, observation, done)\n",
    "                if (i_episode + 1) % 100 == 0:                \n",
    "                    print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "                break\n",
    "        rewards.append(total_r)\n",
    "    env.close()\n",
    "    return rewards\n",
    "rewards_A2C = learn_episodic_A2C(N_EPS, 500)\n",
    "plt.plot(rewards_A2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "try to train the model on r + V(x') - V(x) advantage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
