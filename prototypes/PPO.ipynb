{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./asd.png\" style=\"width: 70%\"> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsss [-0.03839568  0.01818226  0.00893723  0.04159443]\n",
      "obsss [-0.03803204  0.21317492  0.00976912 -0.24825536]\n",
      "obsss [-0.03376854  0.408156    0.00480401 -0.53784096]\n",
      "obsss [-0.02560542  0.21296684 -0.0059528  -0.24364822]\n",
      "obsss [-0.02134608  0.40817331 -0.01082577 -0.53820285]\n",
      "obsss [-0.01318262  0.60344577 -0.02158983 -0.83427709]\n",
      "obsss [-0.0011137   0.40862534 -0.03827537 -0.54846146]\n",
      "obsss [ 0.00705881  0.60426349 -0.0492446  -0.85295397]\n",
      "obsss [ 0.01914408  0.40984616 -0.06630368 -0.57615357]\n",
      "obsss [ 0.027341    0.60583181 -0.07782675 -0.8889651 ]\n",
      "obsss [ 0.03945764  0.80191874 -0.09560605 -1.20506313]\n",
      "obsss [ 0.05549601  0.9981374  -0.11970731 -1.52611237]\n",
      "obsss [ 0.07545876  0.80464644 -0.15022956 -1.27306292]\n",
      "obsss [ 0.09155169  1.00133162 -0.17569082 -1.60876926]\n",
      "obsss [ 0.11157832  0.80866715 -0.2078662  -1.37560914]\n",
      "obsss [ 0.01541248 -0.04975963 -0.01042227 -0.04581637]\n",
      "obsss [ 0.01441729 -0.24473059 -0.0113386   0.2435601 ]\n",
      "obsss [ 0.00952267 -0.04944854 -0.00646739 -0.05267763]\n",
      "obsss [ 0.0085337   0.14576555 -0.00752095 -0.34739404]\n",
      "obsss [ 0.01144901 -0.04924863 -0.01446883 -0.05709219]\n",
      "obsss [ 0.01046404  0.14607776 -0.01561067 -0.35430479]\n",
      "obsss [ 0.0133856  -0.04881878 -0.02269677 -0.06658494]\n",
      "obsss [ 0.01240922 -0.2436081  -0.02402847  0.2188515 ]\n",
      "obsss [ 0.00753706 -0.04815105 -0.01965144 -0.08131312]\n",
      "obsss [ 0.00657404 -0.24298587 -0.0212777   0.20510552]\n",
      "obsss [ 0.00171432 -0.0475662  -0.01717559 -0.0942128 ]\n",
      "obsss [ 0.000763    0.14779766 -0.01905984 -0.39226474]\n",
      "obsss [ 0.00371895  0.34318484 -0.02690514 -0.69089553]\n",
      "obsss [ 0.01058265  0.53866958 -0.04072305 -0.99192567]\n",
      "obsss [ 0.02135604  0.73431211 -0.06056156 -1.29711543]\n",
      "obsss [ 0.03604228  0.93014864 -0.08650387 -1.6081259 ]\n",
      "obsss [ 0.05464525  1.12617996 -0.11866639 -1.92647384]\n",
      "obsss [ 0.07716885  1.32235798 -0.15719587 -2.25347751]\n",
      "obsss [ 0.10361601  1.12902459 -0.20226542 -2.01307857]\n",
      "obsss [ 0.00668749  0.00272691 -0.02123945 -0.00978532]\n",
      "obsss [ 0.00674202  0.19814693 -0.02143515 -0.30909316]\n",
      "obsss [ 0.01070496  0.00333684 -0.02761701 -0.02324661]\n",
      "obsss [ 0.0107717   0.19884374 -0.02808195 -0.3245135 ]\n",
      "obsss [ 0.01474857  0.00413266 -0.03457222 -0.04081704]\n",
      "obsss [ 0.01483123 -0.19047691 -0.03538856  0.24076068]\n",
      "obsss [ 0.01102169  0.00513222 -0.03057334 -0.06287138]\n",
      "obsss [ 0.01112433  0.20067888 -0.03183077 -0.36504145]\n",
      "obsss [ 0.01513791  0.0060234  -0.0391316  -0.08256282]\n",
      "obsss [ 0.01525838 -0.18851639 -0.04078286  0.19752173]\n",
      "obsss [ 0.01148805 -0.383032   -0.03683242  0.47706569]\n",
      "obsss [ 0.00382741 -0.57761506 -0.02729111  0.75791604]\n",
      "obsss [-0.00772489 -0.38212786 -0.01213279  0.45677184]\n",
      "obsss [-0.01536745 -0.57707619 -0.00299735  0.74560586]\n",
      "obsss [-0.02690897 -0.77215665  0.01191477  1.03734402]\n",
      "obsss [-0.0423521  -0.57719508  0.03266165  0.74842528]\n",
      "obsss [-0.05389601 -0.38253855  0.04763015  0.46619703]\n",
      "obsss [-0.06154678 -0.18812081  0.05695409  0.18889912]\n",
      "obsss [-0.06530919 -0.38400937  0.06073207  0.49899099]\n",
      "obsss [-0.07298938 -0.57993262  0.07071189  0.81017829]\n",
      "obsss [-0.08458803 -0.77594846  0.08691546  1.12423926]\n",
      "obsss [-0.100107   -0.97209545  0.10940025  1.44287012]\n",
      "obsss [-0.11954891 -1.16838091  0.13825765  1.76763768]\n",
      "obsss [-0.14291653 -1.36476745  0.1736104   2.09992489]\n",
      "obsss [ 0.03437457 -0.04542423 -0.03931862 -0.02982549]\n",
      "obsss [ 0.03346609 -0.23996092 -0.03991513  0.25019731]\n",
      "obsss [ 0.02866687 -0.43449081 -0.03491118  0.5300278 ]\n",
      "obsss [ 0.01997705 -0.62910471 -0.02431063  0.81150897]\n",
      "obsss [ 0.00739496 -0.82388534 -0.00808045  1.09644697]\n",
      "obsss [-0.00908275 -1.01889996  0.01384849  1.38658371]\n",
      "obsss [-0.02946075 -1.21419178  0.04158016  1.68356468]\n",
      "obsss [-0.05374458 -1.40976969  0.07525146  1.98889902]\n",
      "obsss [-0.08193998 -1.60559566  0.11502944  2.30390974]\n",
      "obsss [-0.11405189 -1.80156951  0.16110763  2.62967197]\n",
      "obsss [-0.04850394  0.01050748  0.04766045 -0.04073872]\n",
      "obsss [-0.04829379  0.20491473  0.04684567 -0.3180116 ]\n",
      "obsss [-0.0441955   0.39933925  0.04048544 -0.59556085]\n",
      "obsss [-0.03620871  0.20367478  0.02857423 -0.29040516]\n",
      "obsss [-0.03213522  0.00815728  0.02276612  0.01115104]\n",
      "obsss [-0.03197207  0.20294546  0.02298914 -0.27426285]\n",
      "obsss [-0.02791316  0.00750317  0.01750389  0.02558133]\n",
      "obsss [-0.0277631   0.20236979  0.01801551 -0.26152793]\n",
      "obsss [-0.0237157   0.39723     0.01278495 -0.54847455]\n",
      "obsss [-0.0157711   0.2019308   0.00181546 -0.25179102]\n",
      "obsss [-0.01173249  0.00678297 -0.00322036  0.04146399]\n",
      "obsss [-0.01159683 -0.18829265 -0.00239108  0.33312913]\n",
      "obsss [-0.01536268 -0.38338049  0.00427151  0.62505707]\n",
      "obsss [-0.02303029 -0.57856181  0.01677265  0.9190822 ]\n",
      "obsss [-0.03460153 -0.77390642  0.03515429  1.21698882]\n",
      "obsss [-0.05007966 -0.96946366  0.05949407  1.52047668]\n",
      "obsss [-0.06946893 -1.16525207  0.0899036   1.83112064]\n",
      "obsss [-0.09277397 -1.36124714  0.12652601  2.15032198]\n",
      "obsss [-0.11999891 -1.55736659  0.16953245  2.47924905]\n",
      "obsss [-0.03146759  0.01449919 -0.02455106  0.03690499]\n",
      "obsss [-0.03117761  0.20996444 -0.02381296 -0.26342183]\n",
      "obsss [-0.02697832  0.01519035 -0.0290814   0.02165614]\n",
      "obsss [-0.02667451 -0.17950274 -0.02864828  0.30502356]\n",
      "obsss [-0.03026457  0.01601551 -0.02254781  0.00344509]\n",
      "obsss [-0.02994426  0.21145345 -0.0224789  -0.2962658 ]\n",
      "obsss [-0.02571519  0.01665904 -0.02840422 -0.01075625]\n",
      "obsss [-0.02538201 -0.17804428 -0.02861935  0.27283121]\n",
      "obsss [-0.02894289 -0.37274642 -0.02316272  0.55635189]\n",
      "obsss [-0.03639782 -0.56753566 -0.01203568  0.84164813]\n",
      "obsss [-0.04774854 -0.76249127  0.00479728  1.13052195]\n",
      "obsss [-0.06299836 -0.95767571  0.02740772  1.42470564]\n",
      "obsss [-0.08215187 -0.76290306  0.05590183  1.14071326]\n",
      "obsss [-0.09740994 -0.9587094   0.0787161   1.45039054]\n",
      "obsss [-0.11658412 -1.15470553  0.10772391  1.76659303]\n",
      "obsss [-0.13967823 -1.3508672   0.14305577  2.09073953]\n",
      "obsss [-0.16669558 -1.54711305  0.18487056  2.4240164 ]\n",
      "obsss [ 0.02519848 -0.01582797 -0.00433166  0.0100577 ]\n",
      "obsss [ 0.02488192 -0.21088753 -0.0041305   0.3013708 ]\n",
      "obsss [ 0.02066417 -0.40595037  0.00189691  0.59274819]\n",
      "obsss [ 0.01254516 -0.60109882  0.01375188  0.88602804]\n",
      "obsss [ 5.23186978e-04 -7.96404734e-01  3.14724386e-02  1.18300214e+00]\n",
      "obsss [-0.01540491 -0.99192062  0.05513248  1.4853821 ]\n",
      "obsss [-0.03524332 -1.18766954  0.08484012  1.79476009]\n",
      "obsss [-0.05899671 -1.38363313  0.12073532  2.11256131]\n",
      "obsss [-0.08666937 -1.18990714  0.16298655  1.85949772]\n",
      "obsss [-0.11046752 -1.38639943  0.20017651  2.19803618]\n",
      "obsss [-0.02623616 -0.04657042  0.03293595  0.02326976]\n",
      "obsss [-0.02716757  0.14806409  0.03340134 -0.25884226]\n",
      "obsss [-0.02420628  0.34269368  0.0282245  -0.54080563]\n",
      "obsss [-0.01735241  0.53740777  0.01740838 -0.82446354]\n",
      "obsss [-0.00660426  0.34205208  0.00091911 -0.5263566 ]\n",
      "obsss [ 0.00023679  0.14691721 -0.00960802 -0.2333842 ]\n",
      "obsss [ 0.00317513  0.34217512 -0.0142757  -0.52908226]\n",
      "obsss [ 0.01001863  0.53749496 -0.02485735 -0.82622909]\n",
      "obsss [ 0.02076853  0.34272161 -0.04138193 -0.54146662]\n",
      "obsss [ 0.02762296  0.53840002 -0.05221126 -0.84689577]\n",
      "obsss [ 0.03839096  0.34402771 -0.06914918 -0.57107775]\n",
      "obsss [ 0.04527152  0.14994012 -0.08057073 -0.30095578]\n",
      "obsss [ 0.04827032  0.34611248 -0.08658985 -0.61792191]\n",
      "obsss [ 0.05519257  0.15230001 -0.09894829 -0.35371801]\n",
      "obsss [ 0.05823857  0.34867949 -0.10602265 -0.67588973]\n",
      "obsss [ 0.06521216  0.15517809 -0.11954044 -0.41837972]\n",
      "obsss [ 0.06831572  0.35177319 -0.12790804 -0.74622913]\n",
      "obsss [ 0.07535119  0.54840618 -0.14283262 -1.07627165]\n",
      "obsss [ 0.08631931  0.74509632 -0.16435805 -1.41015261]\n",
      "obsss [ 0.10122124  0.94183038 -0.1925611  -1.7493808 ]\n",
      "obsss [0.01246973 0.04254931 0.04208216 0.04478986]\n",
      "obsss [ 0.01332071  0.23704335  0.04297796 -0.23432441]\n",
      "obsss [0.01806158 0.04133452 0.03829147 0.07159938]\n",
      "obsss [ 0.01888827 -0.15431488  0.03972346  0.37611329]\n",
      "obsss [0.01580197 0.04022101 0.04724572 0.09621528]\n",
      "obsss [ 0.01660639 -0.15554513  0.04917003  0.40342189]\n",
      "obsss [ 0.01349549 -0.3513287   0.05723847  0.71119248]\n",
      "obsss [ 0.00646892 -0.54719461  0.07146232  1.02132912]\n",
      "obsss [-0.00447498 -0.74319217  0.0918889   1.33556713]\n",
      "obsss [-0.01933882 -0.93934401  0.11860024  1.65553092]\n",
      "obsss [-0.0381257  -0.74578895  0.15171086  1.40202463]\n",
      "obsss [-0.05304148 -0.94243496  0.17975135  1.73803771]\n",
      "obsss [-0.03551164  0.01986259  0.04070427  0.04694189]\n",
      "obsss [-0.03511439 -0.17581868  0.04164311  0.35218442]\n",
      "obsss [-0.03863077 -0.37150731  0.0486868   0.65770242]\n",
      "obsss [-0.04606091 -0.17709565  0.06184085  0.38073876]\n",
      "obsss [-0.04960282  0.01709614  0.06945562  0.1081775 ]\n",
      "obsss [-0.0492609   0.2111576   0.07161917 -0.16180931]\n",
      "obsss [-0.04503775  0.40518507  0.06838299 -0.43106637]\n",
      "obsss [-0.03693405  0.20916481  0.05976166 -0.11763426]\n",
      "obsss [-0.03275075  0.40338185  0.05740897 -0.39088027]\n",
      "obsss [-0.02468312  0.59764403  0.04959137 -0.66492453]\n",
      "obsss [-0.01273023  0.40186862  0.03629288 -0.35704855]\n",
      "obsss [-0.00469286  0.5964563   0.02915191 -0.6380701 ]\n",
      "obsss [ 0.00723626  0.79115988  0.0163905  -0.92143193]\n",
      "obsss [ 0.02305946  0.59582032 -0.00203813 -0.62364336]\n",
      "obsss [ 0.03497587  0.40072689 -0.014511   -0.33160303]\n",
      "obsss [ 0.04299041  0.59605235 -0.02114306 -0.62882646]\n",
      "obsss [ 0.05491145  0.79146289 -0.03371959 -0.92809235]\n",
      "obsss [ 0.07074071  0.59681202 -0.05228144 -0.6461937 ]\n",
      "obsss [ 0.08267695  0.79262198 -0.06520531 -0.95487106]\n",
      "obsss [ 0.09852939  0.59843488 -0.08430273 -0.6833662 ]\n",
      "obsss [ 0.11049809  0.40457845 -0.09797006 -0.41836989]\n",
      "obsss [ 0.11858966  0.60094229 -0.10633746 -0.74026038]\n",
      "obsss [ 0.1306085   0.40743666 -0.12114266 -0.48284579]\n",
      "obsss [ 0.13875724  0.21421411 -0.13079958 -0.23066499]\n",
      "obsss [ 0.14304152  0.41093896 -0.13541288 -0.56157713]\n",
      "obsss [ 0.1512603   0.60767539 -0.14664442 -0.89367011]\n",
      "obsss [ 0.1634138   0.41481396 -0.16451782 -0.65044206]\n",
      "obsss [ 0.17171008  0.61179878 -0.17752666 -0.99007994]\n",
      "obsss [ 0.18394606  0.80879515 -0.19732826 -1.33284947]\n",
      "obsss [-0.00234256  0.03119848  0.03150779  0.02155511]\n",
      "obsss [-0.00171859  0.22585474  0.03193889 -0.2610226 ]\n",
      "obsss [ 0.00279851  0.42050655  0.02671844 -0.54346297]\n",
      "obsss [ 0.01120864  0.61524303  0.01584918 -0.82760915]\n",
      "obsss [ 2.35134995e-02  8.10144727e-01 -7.03000237e-04 -1.11526551e+00]\n",
      "obsss [ 0.03971639  0.61503201 -0.02300831 -0.82280319]\n",
      "obsss [ 0.05201703  0.81046106 -0.03946437 -1.12263301]\n",
      "obsss [ 0.06822626  0.61587815 -0.06191703 -0.84258542]\n",
      "obsss [ 0.08054382  0.81178807 -0.07876874 -1.15407916]\n",
      "obsss [ 0.09677958  1.00784394 -0.10185033 -1.47038519]\n",
      "obsss [ 0.11693646  1.20405361 -0.13125803 -1.79306674]\n",
      "obsss [ 0.14101753  1.40037984 -0.16711936 -2.12350204]\n",
      "obsss [0.04173775 0.00015221 0.01294767 0.01643725]\n",
      "obsss [ 0.0417408  -0.19515301  0.01327642  0.31317703]\n",
      "obsss [ 0.03783774 -0.39046156  0.01953996  0.61001718]\n",
      "obsss [ 0.03002851 -0.19561811  0.0317403   0.3235522 ]\n",
      "obsss [ 0.02611614 -0.39117731  0.03821135  0.62607332]\n",
      "obsss [ 0.0182926  -0.58681124  0.05073281  0.9305414 ]\n",
      "obsss [ 0.00655637 -0.78257984  0.06934364  1.23872554]\n",
      "obsss [-0.00909522 -0.97852054  0.09411815  1.55230093]\n",
      "obsss [-0.02866564 -1.17463666  0.12516417  1.87280303]\n",
      "obsss [-0.05215837 -0.98108459  0.16262023  1.62144838]\n",
      "obsss [-0.07178006 -1.17770545  0.1950492   1.96008837]\n",
      "obsss [ 0.01695503  0.03525865 -0.0065054   0.02104014]\n",
      "obsss [ 0.01766021 -0.1597694  -0.0060846   0.31166346]\n",
      "obsss [ 1.44648180e-02 -3.54804143e-01  1.48669309e-04  6.02421291e-01]\n",
      "obsss [ 0.00736874 -0.15968427  0.0121971   0.3097852 ]\n",
      "obsss [ 0.00417505 -0.35497786  0.0183928   0.60628965]\n",
      "obsss [-0.00292451 -0.5503521   0.03051859  0.90470862]\n",
      "obsss [-0.01393155 -0.74587378  0.04861276  1.20682563]\n",
      "obsss [-0.02884903 -0.94158894  0.07274928  1.51433809]\n",
      "obsss [-0.0476808  -1.13751219  0.10303604  1.82881505]\n",
      "obsss [-0.07043105 -1.33361399  0.13961234  2.15164672]\n",
      "obsss [-0.09710333 -1.52980574  0.18264527  2.48398374]\n",
      "obsss [-0.03144023 -0.0415671   0.01032834 -0.0396081 ]\n",
      "obsss [-0.03227157 -0.23683563  0.00953618  0.25631554]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/distiller/project/conda/conda-bld/pytorch_1565272526878/work/aten/src/TH/generic/THTensorRandom.cpp:356",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ea726d90b703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mN_EPS\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mrewards_A2C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_episodic_A2C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_A2C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ea726d90b703>\u001b[0m in \u001b[0;36mlearn_episodic_A2C\u001b[0;34m(N_eps, max_ep_steps)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'obsss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ea726d90b703>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSavedAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gym/lib/python3.7/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprobs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msample_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: invalid multinomial distribution (encountering probability entry < 0) at /Users/distiller/project/conda/conda-bld/pytorch_1565272526878/work/aten/src/TH/generic/THTensorRandom.cpp:356"
     ]
    }
   ],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.action_head = nn.Linear(128, 2)\n",
    "        self.value_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x, only_value=False):\n",
    "        \n",
    "        # used to compute for the target for the training for A2C\n",
    "        if only_value:\n",
    "            with torch.no_grad():\n",
    "                x = F.relu(self.affine1(x))\n",
    "                return self.value_head(x)\n",
    "            \n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.action_head(x)\n",
    "        state_values = self.value_head(x)\n",
    "        return F.softmax(action_scores, dim=-1), state_values\n",
    "\n",
    "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])\n",
    "\n",
    "policy = Policy()\n",
    "optimizer = optim.RMSprop(policy.parameters(), lr=3e-3)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "def select_action(state):\n",
    "    state = torch.from_numpy(state).float()\n",
    "    probs, state_value = policy(state)\n",
    "    m = Categorical(probs)\n",
    "    \n",
    "    action = m.sample()\n",
    "    policy.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "    return action.item()\n",
    "\n",
    "\"GIVEN rewards array from rollout return the returns with zero mean and unit std\"        \n",
    "def discount_rewards(rewards_arr, gamma, init_reward=0):\n",
    "    R = init_reward\n",
    "    returns = []\n",
    "    for r in rewards_arr[::-1]:\n",
    "        R = r + R*gamma\n",
    "        returns.insert(0, R)\n",
    "#     print('rewards_arr', rewards_arr)\n",
    "#     print('rrrr', returns)\n",
    "    returns = torch.tensor(returns)\n",
    "    return (returns - returns.mean())/(returns.std() + eps)\n",
    "\n",
    "def train_on_rollout(gamma=0.99):\n",
    "    returns = discount_rewards(policy.rewards, gamma)\n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.smooth_l1_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.stack(actor_loss).sum() + torch.stack(critic_loss).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "    \n",
    "def n_step_train(observation, done, gamma = 0.99):\n",
    "    if done:\n",
    "        final_value = 0\n",
    "    else:\n",
    "        final_value = torch.from_numpy(observation).float()\n",
    "        final_value = policy.forward(final_value, only_value=True).item()\n",
    "    \n",
    "    returns = discount_rewards(policy.rewards, gamma, final_value)\n",
    "    \n",
    "    actor_loss = []\n",
    "    critic_loss = []\n",
    "    for (log_prob, value), r in zip(policy.saved_actions, returns):\n",
    "        advantage = r - value.item()\n",
    "        actor_loss.append(-log_prob * advantage)\n",
    "        critic_loss.append(F.mse_loss(value, torch.tensor([r])))\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.mean(torch.stack(actor_loss)) + torch.mean(torch.stack(critic_loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    del policy.rewards[:]\n",
    "    del policy.saved_actions[:]\n",
    "\n",
    "def learn_episodic_A2C(N_eps=500, max_ep_steps=500):\n",
    "    df = 0.99\n",
    "    rewards = []\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env._max_episode_steps = max_ep_steps\n",
    "    batch_size_updates = 10\n",
    "    i = 0\n",
    "    for i_episode in range(N_eps):\n",
    "        observation = env.reset()\n",
    "        total_r = 0\n",
    "        for t in range(100000):\n",
    "            i += 1\n",
    "            print('obsss', observation)\n",
    "            action = select_action(observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            policy.rewards.append(reward)\n",
    "            total_r += reward\n",
    "#             dones.append(done)\n",
    "            if (i % batch_size_updates) == 0 or done:\n",
    "#                 print('1,', observation)\n",
    "                n_step_train(observation, done, df)\n",
    "#                 print('2, ', observation)\n",
    "            if done:\n",
    "#                 train_on_rollout(0.99)\n",
    "                if (i_episode + 1) % 100 == 0:                \n",
    "                    print(\"Episode {} finished after {} timesteps\".format(i_episode, t+1))\n",
    "                break\n",
    "        rewards.append(total_r)\n",
    "    env.close()\n",
    "    return rewards\n",
    "\n",
    "N_EPS= 500\n",
    "rewards_A2C = learn_episodic_A2C(N_EPS, 500)\n",
    "plt.plot(rewards_A2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "try to train the model on r + V(x') - V(x) advantage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}